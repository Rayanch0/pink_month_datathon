{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Path to the directory containing your CSV file\n",
    "base_dir = 'C:\\\\Users\\\\LENOVO\\\\OneDrive\\\\Desktop'\n",
    "csv_path = os.path.join(base_dir, 'train_data.csv')\n",
    "\n",
    "# Load dataset CSV\n",
    "train_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Path to the directories containing images\n",
    "image_dir_benign = 'C:\\\\Users\\\\LENOVO\\\\OneDrive\\\\Desktop\\\\breast-cancer-detection-challenge\\\\data\\\\train\\\\0'\n",
    "image_dir_malignant = 'C:\\\\Users\\\\LENOVO\\\\OneDrive\\\\Desktop\\\\breast-cancer-detection-challenge\\\\data\\\\train\\\\1'\n",
    "\n",
    "# Function to load images from both folders with debug prints\n",
    "def load_images(df, dir_benign, dir_malignant, target_size=(224, 224)):\n",
    "    images = []\n",
    "    labels = df['label'].values\n",
    "    for img_name in df['file_name']:\n",
    "        img_path_benign = os.path.join(dir_benign, img_name)\n",
    "        img_path_malignant = os.path.join(dir_malignant, img_name)\n",
    "        if os.path.isfile(img_path_benign):\n",
    "            img_path = img_path_benign\n",
    "        elif os.path.isfile(img_path_malignant):\n",
    "            img_path = img_path_malignant\n",
    "        else:\n",
    "            print(f'File not found: {img_name}')\n",
    "            continue\n",
    "        print(f'Loading: {img_path}')  # Debug print\n",
    "        img = load_img(img_path, target_size=target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        images.append(img_array)\n",
    "    return np.array(images), labels\n",
    "\n",
    "# Load images\n",
    "train_images, train_labels = load_images(train_df, image_dir_benign, image_dir_malignant)\n",
    "print(f'Loaded {len(train_images)} images.')\n",
    "\n",
    "# Proceed if images are successfully loaded\n",
    "if len(train_images) > 0:\n",
    "    # Normalize images\n",
    "    train_images = train_images / 255.0\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    train_labels = to_categorical(train_labels)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # ImageDataGenerator for Data Augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Fit the data generator\n",
    "    train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "    validation_generator = test_datagen.flow(X_test, y_test, batch_size=32)\n",
    "\n",
    "    # Load the VGG16 model\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Add custom layers on top\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Freeze the base model layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Callbacks for early stopping and reducing learning rate\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_generator, epochs=10, validation_data=validation_generator,\n",
    "                        callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    loss, accuracy = model.evaluate(validation_generator)\n",
    "    print(f'Loss: {loss}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "else:\n",
    "    print('No images loaded. Please check your image directory and file paths.')\n",
    "# Path to the new test CSV file\n",
    "test_csv_path = os.path.join(base_dir, 'test_data.csv')\n",
    "\n",
    "# Load the test dataset CSV\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Function to load and preprocess images for the test set\n",
    "def load_test_images(df, dir_benign, dir_malignant, target_size=(224, 224)):\n",
    "    images = []\n",
    "    filenames = df['file_name'].values\n",
    "    for img_name in filenames:\n",
    "        img_path_benign = os.path.join(dir_benign, img_name)\n",
    "        img_path_malignant = os.path.join(dir_malignant, img_name)\n",
    "        if os.path.isfile(img_path_benign):\n",
    "            img_path = img_path_benign\n",
    "        elif os.path.isfile(img_path_malignant):\n",
    "            img_path = img_path_malignant\n",
    "        else:\n",
    "            print(f'File not found: {img_name}')\n",
    "            continue\n",
    "        print(f'Loading: {img_path}')  # Debug print\n",
    "        img = load_img(img_path, target_size=target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        images.append(img_array)\n",
    "    return np.array(images), filenames\n",
    "\n",
    "# Load test images\n",
    "test_images, test_filenames = load_test_images(test_df, image_dir_benign, image_dir_malignant)\n",
    "\n",
    "# Normalize test images\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Predict labels for the test set\n",
    "test_predictions = model.predict(test_images)\n",
    "predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Create a submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'file_name': test_filenames,\n",
    "    'label': predicted_labels\n",
    "})\n",
    "\n",
    "# Path to the submission CSV file\n",
    "submission_csv_path = os.path.join(base_dir, 'submission.csv')\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission_df.to_csv(submission_csv_path, index=False)\n",
    "\n",
    "print(f'Submission file saved to {submission_csv_path}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
